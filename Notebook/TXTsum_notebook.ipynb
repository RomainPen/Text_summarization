{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Conversation summarization project (BART and T5)"]},{"cell_type":"raw","metadata":{},"source":["df_train : set for training (train part), 100% of conv_train.parquet\n","df_val1 : set for training (val part), 100% of conv_val.parquet\n","df_val2 : set for model validation, 100% of conv_test.parquet\n","\n","df_val2_test (imported later): same set of the df_val2, but use for deployment testing, 100% of conv_test.parquet"]},{"cell_type":"markdown","metadata":{},"source":["## 0/ Config Google colab and Google drive"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T10:46:09.797763Z","iopub.status.busy":"2024-06-22T10:46:09.797424Z","iopub.status.idle":"2024-06-22T10:46:09.803091Z","shell.execute_reply":"2024-06-22T10:46:09.802068Z","shell.execute_reply.started":"2024-06-22T10:46:09.797734Z"},"trusted":true},"outputs":[],"source":["# # Config Google_colab and Google_drive :\n","# from google.colab import drive\n","# drive.mount('/content/drive')\n","\n","# #change directory :\n","# os.chdir(r'./drive/MyDrive/Data_science/PROJET_perso/NLP_project/Notebook')"]},{"cell_type":"markdown","metadata":{},"source":["## 1/ Import package"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T10:46:09.807018Z","iopub.status.busy":"2024-06-22T10:46:09.806657Z","iopub.status.idle":"2024-06-22T10:46:10.607830Z","shell.execute_reply":"2024-06-22T10:46:10.606880Z","shell.execute_reply.started":"2024-06-22T10:46:09.806992Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'/kaggle/working'"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","import os \n","os.getcwd()"]},{"cell_type":"markdown","metadata":{},"source":["## 2/ Collect data"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T10:46:10.610062Z","iopub.status.busy":"2024-06-22T10:46:10.609634Z","iopub.status.idle":"2024-06-22T10:46:11.005267Z","shell.execute_reply":"2024-06-22T10:46:11.004352Z","shell.execute_reply.started":"2024-06-22T10:46:10.610026Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>dialogue</th>\n","      <th>summary</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>13818513</td>\n","      <td>Amanda: I baked  cookies. Do you want some?\\nJ...</td>\n","      <td>Amanda baked cookies and will bring Jerry some...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>13728867</td>\n","      <td>Olivia: Who are you voting for in this electio...</td>\n","      <td>Olivia and Olivier are voting for liberals in ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>13681000</td>\n","      <td>Tim: Hi, what's up?\\nKim: Bad mood tbh, I was ...</td>\n","      <td>Kim may try the pomodoro technique recommended...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>13730747</td>\n","      <td>Edward: Rachel, I think I'm in ove with Bella....</td>\n","      <td>Edward thinks he is in love with Bella. Rachel...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>13728094</td>\n","      <td>Sam: hey  overheard rick say something\\nSam: i...</td>\n","      <td>Sam is confused, because he overheard Rick com...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>14727</th>\n","      <td>13863028</td>\n","      <td>Romeo: You are on my ‘People you may know’ lis...</td>\n","      <td>Romeo is trying to get Greta to add him to her...</td>\n","    </tr>\n","    <tr>\n","      <th>14728</th>\n","      <td>13828570</td>\n","      <td>Theresa: &lt;file_photo&gt;\\nTheresa: &lt;file_photo&gt;\\n...</td>\n","      <td>Theresa is at work. She gets free food and fre...</td>\n","    </tr>\n","    <tr>\n","      <th>14729</th>\n","      <td>13819050</td>\n","      <td>John: Every day some bad news. Japan will hunt...</td>\n","      <td>Japan is going to hunt whales again. Island an...</td>\n","    </tr>\n","    <tr>\n","      <th>14730</th>\n","      <td>13828395</td>\n","      <td>Jennifer: Dear Celia! How are you doing?\\nJenn...</td>\n","      <td>Celia couldn't make it to the afternoon with t...</td>\n","    </tr>\n","    <tr>\n","      <th>14731</th>\n","      <td>13729017</td>\n","      <td>Georgia: are you ready for hotel hunting? We n...</td>\n","      <td>Georgia and Juliette are looking for a hotel i...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>14732 rows × 3 columns</p>\n","</div>"],"text/plain":["             id                                           dialogue  \\\n","0      13818513  Amanda: I baked  cookies. Do you want some?\\nJ...   \n","1      13728867  Olivia: Who are you voting for in this electio...   \n","2      13681000  Tim: Hi, what's up?\\nKim: Bad mood tbh, I was ...   \n","3      13730747  Edward: Rachel, I think I'm in ove with Bella....   \n","4      13728094  Sam: hey  overheard rick say something\\nSam: i...   \n","...         ...                                                ...   \n","14727  13863028  Romeo: You are on my ‘People you may know’ lis...   \n","14728  13828570  Theresa: <file_photo>\\nTheresa: <file_photo>\\n...   \n","14729  13819050  John: Every day some bad news. Japan will hunt...   \n","14730  13828395  Jennifer: Dear Celia! How are you doing?\\nJenn...   \n","14731  13729017  Georgia: are you ready for hotel hunting? We n...   \n","\n","                                                 summary  \n","0      Amanda baked cookies and will bring Jerry some...  \n","1      Olivia and Olivier are voting for liberals in ...  \n","2      Kim may try the pomodoro technique recommended...  \n","3      Edward thinks he is in love with Bella. Rachel...  \n","4      Sam is confused, because he overheard Rick com...  \n","...                                                  ...  \n","14727  Romeo is trying to get Greta to add him to her...  \n","14728  Theresa is at work. She gets free food and fre...  \n","14729  Japan is going to hunt whales again. Island an...  \n","14730  Celia couldn't make it to the afternoon with t...  \n","14731  Georgia and Juliette are looking for a hotel i...  \n","\n","[14732 rows x 3 columns]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# import data (training part) : \n","\n","df_train = pd.read_parquet(r\"/kaggle/input/data-txt-summarisation/Data/training_data/conv_train.parquet\", engine=\"pyarrow\")\n","df_val1 = pd.read_parquet(r\"/kaggle/input/data-txt-summarisation/Data/training_data/conv_val1.parquet\", engine=\"pyarrow\")\n","df_val2 = pd.read_parquet(r\"/kaggle/input/data-txt-summarisation/Data/training_data/conv_val2.parquet\", engine=\"pyarrow\")\n","\n","df_train"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T10:46:11.012134Z","iopub.status.busy":"2024-06-22T10:46:11.011227Z","iopub.status.idle":"2024-06-22T10:46:11.019264Z","shell.execute_reply":"2024-06-22T10:46:11.018352Z","shell.execute_reply.started":"2024-06-22T10:46:11.012088Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["dialogue : \n","Oli: I've talked to some people from the third year\n","Jacob: About the statistics exam?\n","Marcia: What did they say?\n","Oli: Yeah, about the exam\n","Oli: We need to prepare for a battle\n","Jacob: So it will be difficult\n","Oli: They said it was the hardest exam ever\n","Marcia: 😱\n","Oli: The questions were displayed on the screen \n","Oli: One minute per question and it disappears\n","Oli: They won't come back so if you didn't get your answer you're fucked\n","Marcia: So we need to make the calculations really fast\n","Jacob: That's insane\n","Oli: I know\n","Oli: Very stressful\n","Marcia: How are we even supposed to study for it?\n","Marcia: With a timer?\n","Oli: I guess\n","Marcia: Did anybody pass it last year\n","Oli: Some people did, but the majority had to take the second or even the third chance\n"," \n","summary : \n","Oli, Jacob and Marcia have to prepare for a very hard statistics exam. Last year, people had only one minute to answer each question and then it disappeared.\n"]}],"source":["# Analyse some examples :\n","def print_example(df, txt_id) : \n","    print(f\"dialogue : \\n{df['dialogue'].loc[txt_id]}\")\n","    print(\" \")\n","    print(f\"summary : \\n{df['summary'].loc[txt_id]}\")\n","\n","print_example(df_train, 60)"]},{"cell_type":"markdown","metadata":{},"source":["## 3/ Split df into df_train/df_val1/df_val2 : (already done)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## 4.1/ Data cleaning 1"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T10:46:11.021958Z","iopub.status.busy":"2024-06-22T10:46:11.021138Z","iopub.status.idle":"2024-06-22T10:46:11.027449Z","shell.execute_reply":"2024-06-22T10:46:11.026543Z","shell.execute_reply.started":"2024-06-22T10:46:11.021922Z"},"trusted":true},"outputs":[],"source":["# rename col [df_train.rename(columns={\"A\": \"a\", \"B\": \"c\"})] : {\"A\": \"a\", \"B\": \"c\"}\n","col_to_rename = {\"id\" : \"id\", \"dialogue\" : \"dialogue\", \"summary\" : \"summary\"}\n","\n","# Check and change col type (with new col name):\n","col_type = {\"id\" : \"object\", \"dialogue\" : \"object\", \"summary\" : \"object\"}\n","\n","# Useless columns (set) : {}\n","useless_columns = None"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T10:46:11.029179Z","iopub.status.busy":"2024-06-22T10:46:11.028835Z","iopub.status.idle":"2024-06-22T10:46:11.081764Z","shell.execute_reply":"2024-06-22T10:46:11.080932Z","shell.execute_reply.started":"2024-06-22T10:46:11.029146Z"},"trusted":true},"outputs":[],"source":["# Data cleaning function : \n","def data_cleaning_1(df, col_to_rename=None, col_type=None, useless_columns=None):\n","    \n","    # Deep copy : \n","    df_new = df.copy()\n","    \n","    # Rename columns if col_to_rename is provided and not empty\n","    if col_to_rename:\n","        df_new = df_new.rename(columns=col_to_rename)\n","    \n","    # Check and change column types if col_type is provided\n","    if col_type:\n","        for col in df_new.columns : \n","            df_new[col] = df_new[col].astype(col_type[col])\n","            \n","    # Remove duplicates\n","    df_new = df_new.drop_duplicates().reset_index(drop=True)\n","    \n","    # Drop useless columns if useless_columns is provided\n","    if useless_columns:\n","        df_new = df_new.drop(list(useless_columns), axis=1)\n","    \n","    # Remove rows with NaN in \"dialogue\" or \"summary\"\n","    df_new = df_new.dropna(subset=[\"dialogue\", \"summary\"], ignore_index=True).reset_index(drop=True)\n","    \n","    return df_new\n","\n","\n","kwarg_dc1 = {\"col_to_rename\": col_to_rename, \"col_type\": col_type, \"useless_columns\":useless_columns}\n","df_train = data_cleaning_1(df=df_train, **kwarg_dc1)\n","df_val1 = data_cleaning_1(df=df_val1, **kwarg_dc1)\n","df_val2 = data_cleaning_1(df=df_val2, **kwarg_dc1)\n","\n","\n","# Check Language consistency (english txt == english summary), by hand : #Already done\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## 4.2/ Data cleaning 2"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T10:46:11.083190Z","iopub.status.busy":"2024-06-22T10:46:11.082870Z","iopub.status.idle":"2024-06-22T10:46:12.243108Z","shell.execute_reply":"2024-06-22T10:46:12.241893Z","shell.execute_reply.started":"2024-06-22T10:46:11.083165Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['id', 'dialogue', 'summary'],\n","    num_rows: 14731\n","})"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# Convert df (pandas df format) to Dataset (huggingface format) :\n","from datasets import Dataset\n","\n","dataset_train = Dataset.from_pandas(df_train)\n","dataset_val1 = Dataset.from_pandas(df_val1)\n","dataset_val2 = Dataset.from_pandas(df_val2)\n","\n","dataset_train"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T10:46:12.245017Z","iopub.status.busy":"2024-06-22T10:46:12.244470Z","iopub.status.idle":"2024-06-22T10:46:12.253190Z","shell.execute_reply":"2024-06-22T10:46:12.252062Z","shell.execute_reply.started":"2024-06-22T10:46:12.244985Z"},"trusted":true},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['id', 'dialogue', 'summary'],\n","        num_rows: 14731\n","    })\n","    val1: Dataset({\n","        features: ['id', 'dialogue', 'summary'],\n","        num_rows: 818\n","    })\n","    val2: Dataset({\n","        features: ['id', 'dialogue', 'summary'],\n","        num_rows: 819\n","    })\n","})"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# Concat \"dataset_train, dataset_val1, dataset_val2\" into a DatasetDict : \n","from datasets import DatasetDict\n","Datadict = DatasetDict()\n","\n","Datadict['train'] = dataset_train\n","Datadict['val1'] = dataset_val1\n","Datadict['val2'] = dataset_val2\n","\n","Datadict"]},{"cell_type":"markdown","metadata":{},"source":["### Part 1 :"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T10:46:12.255363Z","iopub.status.busy":"2024-06-22T10:46:12.254717Z","iopub.status.idle":"2024-06-22T10:46:12.263642Z","shell.execute_reply":"2024-06-22T10:46:12.262629Z","shell.execute_reply.started":"2024-06-22T10:46:12.255339Z"},"trusted":true},"outputs":[],"source":["# Example of data processing function : \n","\n","# # example 1 : using function\n","# # 2 (or more) process in one : \n","# def process_example(example):\n","#     summary_lower = [x.lower() for x in example[\"summary\"]]\n","#     summary_length = [len(x.split()) for x in example[\"summary\"]]\n","#     return {\"summary_lower\": summary_lower, \"summary_length\":summary_length}\n","\n","# Datadict = Datadict.map(process_example, batched=True)\n","# Datadict.set_format(\"pandas\")\n","# Datadict[\"train\"][:3]"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T10:46:12.268349Z","iopub.status.busy":"2024-06-22T10:46:12.268047Z","iopub.status.idle":"2024-06-22T10:46:12.277369Z","shell.execute_reply":"2024-06-22T10:46:12.276424Z","shell.execute_reply.started":"2024-06-22T10:46:12.268325Z"},"trusted":true},"outputs":[],"source":["# # example 2 : using lambda\n","# # We use batched=True when we are doing a list comprehension and when the output value is a list.\n","# # And when we do the tokenization\n","\n","# Datadict = Datadict.map(lambda x: {\"abc_list\": [i.split(\"o\") for i in x[\"abc\"]]}, batched=True)\n","# Datadict.set_format(\"pandas\")\n","# Datadict[\"train\"][:3]"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T10:46:12.279392Z","iopub.status.busy":"2024-06-22T10:46:12.279068Z","iopub.status.idle":"2024-06-22T10:46:15.538485Z","shell.execute_reply":"2024-06-22T10:46:15.537612Z","shell.execute_reply.started":"2024-06-22T10:46:12.279364Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"322894cf0f7b4e4b87330f9688dba557","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/14731 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c2f9a0177bcd407d99c5955e219fd3df","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/818 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"94ceada00e7a4537a3cebff40d08b860","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/819 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Normalized txt :\n","import html\n","import re\n","\n","\n","def normalized_txt(df):\n","    processed_dialogue = []\n","    processed_summary = []\n","    \n","    for text in df[\"dialogue\"]:\n","        text = process_text(text)\n","        processed_dialogue.append(text)\n","    \n","    for text in df[\"summary\"]:\n","        text = process_text(text)\n","        processed_summary.append(text)\n","    \n","    return {\"dialogue\": processed_dialogue, \"summary\": processed_summary}\n","\n","\n","\n","def process_text(text):\n","    # Remove HTML tags\n","    text = html.unescape(text)\n","    \n","    # Lowercase\n","    # text = text.lower()\n","    \n","    # Remove extra spaces at the start and end\n","    text = text.strip()\n","    \n","    # Replace control characters (\\r, \\n, \\t) with ' | '\n","    text = re.sub(r'[\\r\\n\\t]', ' | ', text)\n","    \n","    # Remove redundant spaces within the text\n","    text = \" \".join(text.split())\n","    \n","    # STANDARDIZE PUNCTUATION :\n","    # Convert different types of quotation marks and apostrophes to standard forms\n","    text = text.replace('“', '\"').replace('”', '\"')\n","    text = text.replace(\"‘\", \"'\").replace(\"’\", \"'\")\n","    \n","    # Ensure consistent spacing around punctuation\n","    text = re.sub(r'([?.!,%£$€\"])', r'\\1 ', text)  # Remove spaces before punctuation and Ensure space after punctuation (except at end of string)\n","    text = re.sub(r'([&:+-=;])', r' \\1 ', text)\n","    \n","    # Convert special punctuation to standard forms (example: em dash to hyphen)\n","    #text = text.replace('—', '-').replace('–', '-')\n","    \n","    # REMOVE or REPLACE USELESS CHARACTERS :\n","    # Remove URLs\n","    #text = re.sub(r'http\\S+|www\\S+|https\\S+', '<Web_site_link>', text, flags=re.MULTILINE)\n","    \n","    # Remove email addresses\n","    #text = re.sub(r'\\S+@\\S+', '<email_address>', text)\n","    \n","    # Remove non-ASCII characters\n","    text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n","    \n","    return text\n","\n","\n","# Apply the combined function to the dataset\n","Datadict = Datadict.map(normalized_txt, batched=True)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T10:46:15.540450Z","iopub.status.busy":"2024-06-22T10:46:15.539823Z","iopub.status.idle":"2024-06-22T10:46:15.544484Z","shell.execute_reply":"2024-06-22T10:46:15.543622Z","shell.execute_reply.started":"2024-06-22T10:46:15.540417Z"},"trusted":true},"outputs":[],"source":["# Correct spelling and grammar : # Already done\n","# remove noise (jargon, slang, typo) : # Not necessary"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T10:46:15.546052Z","iopub.status.busy":"2024-06-22T10:46:15.545791Z","iopub.status.idle":"2024-06-22T10:46:32.768907Z","shell.execute_reply":"2024-06-22T10:46:32.768026Z","shell.execute_reply.started":"2024-06-22T10:46:15.546030Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1474689ea32144de91fbafd9ac531953","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/14731 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9c953331e7a6459483484b0dffc02cde","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/818 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5fbe139527494abd80b0741baebf0dcd","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/819 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Handle Emoji :\n","import emoji\n","Datadict = Datadict.map(lambda df: {\"dialogue\": [emoji.demojize(txt) for txt in df[\"dialogue\"]]}, batched=True)"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T10:46:32.770333Z","iopub.status.busy":"2024-06-22T10:46:32.770080Z","iopub.status.idle":"2024-06-22T10:46:32.783918Z","shell.execute_reply":"2024-06-22T10:46:32.782778Z","shell.execute_reply.started":"2024-06-22T10:46:32.770311Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>dialogue</th>\n","      <th>summary</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>13818513</td>\n","      <td>Amanda :  I baked cookies .   Do you want some...</td>\n","      <td>Amanda baked cookies and will bring Jerry some...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>13728867</td>\n","      <td>Olivia :  Who are you voting for in this elect...</td>\n","      <td>Olivia and Olivier are voting for liberals in ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>13681000</td>\n","      <td>Tim :  Hi ,   what's up?  | Kim :  Bad mood tb...</td>\n","      <td>Kim may try the pomodoro technique recommended...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         id                                           dialogue  \\\n","0  13818513  Amanda :  I baked cookies .   Do you want some...   \n","1  13728867  Olivia :  Who are you voting for in this elect...   \n","2  13681000  Tim :  Hi ,   what's up?  | Kim :  Bad mood tb...   \n","\n","                                             summary  \n","0  Amanda baked cookies and will bring Jerry some...  \n","1  Olivia and Olivier are voting for liberals in ...  \n","2  Kim may try the pomodoro technique recommended...  "]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["# > Check for consistency (by hand and map) : # Done\n","# > Consistency in Formatting (by hand and map) : # Done\n","Datadict.set_format(\"pandas\")\n","Datadict[\"train\"][:3]"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T10:46:32.785188Z","iopub.status.busy":"2024-06-22T10:46:32.784937Z","iopub.status.idle":"2024-06-22T10:46:32.790021Z","shell.execute_reply":"2024-06-22T10:46:32.789071Z","shell.execute_reply.started":"2024-06-22T10:46:32.785166Z"},"trusted":true},"outputs":[],"source":["# reset to arrow format :\n","Datadict.reset_format()"]},{"cell_type":"markdown","metadata":{},"source":["### Part 2 :"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T10:46:32.791493Z","iopub.status.busy":"2024-06-22T10:46:32.791200Z","iopub.status.idle":"2024-06-22T10:46:32.797979Z","shell.execute_reply":"2024-06-22T10:46:32.796977Z","shell.execute_reply.started":"2024-06-22T10:46:32.791470Z"},"trusted":true},"outputs":[],"source":["# Data filter (select specific text, if necessary) : # Already done"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T10:46:32.799409Z","iopub.status.busy":"2024-06-22T10:46:32.799104Z","iopub.status.idle":"2024-06-22T10:46:32.962231Z","shell.execute_reply":"2024-06-22T10:46:32.961353Z","shell.execute_reply.started":"2024-06-22T10:46:32.799385Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"97e020c1270f487387f9846860c4cce9","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/14731 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f84b60d130274ff1a2678402a458b961","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/818 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"57b64f95fdac41939550f4f3c4f576b3","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/819 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Check the distribution of words in the text and their reference summary (If ref_summary to Short/Long, then delete this row, else keep it) : # everything is good\n","\n","Datadict = Datadict.map(lambda df : {\"len_dialogue\" : [len(txt) for txt in df[\"dialogue\"]], \"len_summary\" : [len(txt) for txt in df[\"summary\"]]}, batched=True)\n","Datadict.set_format(\"pandas\")"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T10:46:32.963546Z","iopub.status.busy":"2024-06-22T10:46:32.963265Z","iopub.status.idle":"2024-06-22T10:46:33.325076Z","shell.execute_reply":"2024-06-22T10:46:33.324189Z","shell.execute_reply.started":"2024-06-22T10:46:32.963523Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<Axes: >"]},"execution_count":18,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","Datadict[\"train\"][\"len_dialogue\"].hist(bins=100)"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T10:46:33.326616Z","iopub.status.busy":"2024-06-22T10:46:33.326239Z","iopub.status.idle":"2024-06-22T10:46:33.674896Z","shell.execute_reply":"2024-06-22T10:46:33.674043Z","shell.execute_reply.started":"2024-06-22T10:46:33.326569Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<Axes: >"]},"execution_count":19,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["Datadict[\"train\"][\"len_summary\"].hist(bins=100)"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T10:46:33.676440Z","iopub.status.busy":"2024-06-22T10:46:33.676109Z","iopub.status.idle":"2024-06-22T10:46:33.686128Z","shell.execute_reply":"2024-06-22T10:46:33.685331Z","shell.execute_reply.started":"2024-06-22T10:46:33.676410Z"},"trusted":true},"outputs":[],"source":["# reset to arrow format :\n","Datadict.reset_format()\n","\n","# Delete col [\"len_dialogue\", \"len_summary\"] : \n","Datadict = Datadict.remove_columns([\"len_dialogue\", \"len_summary\"])"]},{"cell_type":"markdown","metadata":{},"source":["## 5/ Choose the model (BART or T5)"]},{"cell_type":"raw","metadata":{"vscode":{"languageId":"raw"}},"source":["T5 or T5-small"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T10:46:33.687354Z","iopub.status.busy":"2024-06-22T10:46:33.687107Z","iopub.status.idle":"2024-06-22T10:46:33.695831Z","shell.execute_reply":"2024-06-22T10:46:33.694963Z","shell.execute_reply.started":"2024-06-22T10:46:33.687333Z"},"trusted":true},"outputs":[],"source":["# Define the model checkpoint :\n","model_checkpoint = \"google-t5/t5-small\""]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T10:46:33.697295Z","iopub.status.busy":"2024-06-22T10:46:33.697029Z","iopub.status.idle":"2024-06-22T10:46:37.079656Z","shell.execute_reply":"2024-06-22T10:46:37.078721Z","shell.execute_reply.started":"2024-06-22T10:46:33.697270Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'cuda:0'"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["# Define the devise (cuda or CPU) :\n","import torch\n","device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n","device"]},{"cell_type":"markdown","metadata":{},"source":["## 6/ Data pre-processing"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T10:46:37.081640Z","iopub.status.busy":"2024-06-22T10:46:37.080984Z","iopub.status.idle":"2024-06-22T10:46:39.478271Z","shell.execute_reply":"2024-06-22T10:46:39.477411Z","shell.execute_reply.started":"2024-06-22T10:46:37.081605Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"14478725cc034ada8d7622af4c1638e5","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e484a7d50c9049e39fb90ab9c7059e30","version_major":2,"version_minor":0},"text/plain":["spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1810d10745474f13ba6d8a4e2ae28422","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Tokenization :\n","from transformers import AutoTokenizer\n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T10:46:39.480148Z","iopub.status.busy":"2024-06-22T10:46:39.479655Z","iopub.status.idle":"2024-06-22T10:46:39.487282Z","shell.execute_reply":"2024-06-22T10:46:39.486331Z","shell.execute_reply.started":"2024-06-22T10:46:39.480118Z"},"trusted":true},"outputs":[],"source":["max_input_length = 1024\n","max_target_length = 200\n","\n","# Preprocessing function for tokenization\n","def preprocess_function(examples):\n","    # Tokenize the dialogues\n","    model_inputs = tokenizer(\n","        examples[\"dialogue\"],\n","        max_length=max_input_length,\n","        truncation=True,\n","        padding=\"max_length\",  # Ensure all sequences are of equal length => can improve performance during training\n","        return_tensors=\"pt\"  # Return PyTorch tensors \n","    )\n","    \n","    # Tokenize the summaries\n","    labels = tokenizer(\n","        examples[\"summary\"],\n","        max_length=max_target_length,\n","        truncation=True,\n","        padding=\"max_length\",  # Ensure all sequences are of equal length\n","        return_tensors=\"pt\"  # Return PyTorch tensors directly\n","    )\n","\n","    # Set the labels (output_ids)\n","    model_inputs[\"labels\"] = labels[\"input_ids\"] # output_ids <=> labels\n","    return model_inputs\n"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T10:46:39.488725Z","iopub.status.busy":"2024-06-22T10:46:39.488386Z","iopub.status.idle":"2024-06-22T10:46:59.752944Z","shell.execute_reply":"2024-06-22T10:46:59.752034Z","shell.execute_reply.started":"2024-06-22T10:46:39.488698Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2faafeb618504c98896a78d147c5949f","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/14731 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4c905181002d4526873768230e8c2741","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/818 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6cfcf284e4034569b6a6d78c523d7344","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/819 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['id', 'dialogue', 'summary', 'input_ids', 'attention_mask', 'labels'],\n","        num_rows: 14731\n","    })\n","    val1: Dataset({\n","        features: ['id', 'dialogue', 'summary', 'input_ids', 'attention_mask', 'labels'],\n","        num_rows: 818\n","    })\n","    val2: Dataset({\n","        features: ['id', 'dialogue', 'summary', 'input_ids', 'attention_mask', 'labels'],\n","        num_rows: 819\n","    })\n","})"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["tokenized_datasets = Datadict.map(preprocess_function, batched=True)\n","tokenized_datasets"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## 7/ Metrics for text summarization"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T10:46:59.754271Z","iopub.status.busy":"2024-06-22T10:46:59.754021Z","iopub.status.idle":"2024-06-22T10:47:13.277909Z","shell.execute_reply":"2024-06-22T10:47:13.276879Z","shell.execute_reply.started":"2024-06-22T10:46:59.754249Z"},"trusted":true},"outputs":[],"source":["#!pip install evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T10:47:13.279660Z","iopub.status.busy":"2024-06-22T10:47:13.279348Z","iopub.status.idle":"2024-06-22T10:47:27.745654Z","shell.execute_reply":"2024-06-22T10:47:27.744476Z","shell.execute_reply.started":"2024-06-22T10:47:13.279631Z"},"trusted":true},"outputs":[],"source":["#!pip install rouge_score"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T10:47:27.753746Z","iopub.status.busy":"2024-06-22T10:47:27.753408Z","iopub.status.idle":"2024-06-22T10:47:39.974942Z","shell.execute_reply":"2024-06-22T10:47:39.974038Z","shell.execute_reply.started":"2024-06-22T10:47:27.753718Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-06-22 10:47:29.489343: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-06-22 10:47:29.489466: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-06-22 10:47:29.613910: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a0516f3957fd478bb0d60667000c6dd9","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Rouge-score :\n","import evaluate\n","\n","rouge_score = evaluate.load(\"rouge\")"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T10:47:39.976675Z","iopub.status.busy":"2024-06-22T10:47:39.975936Z","iopub.status.idle":"2024-06-22T10:47:40.184408Z","shell.execute_reply":"2024-06-22T10:47:40.183528Z","shell.execute_reply.started":"2024-06-22T10:47:39.976646Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'rouge1': 0.923076923076923,\n"," 'rouge2': 0.7272727272727272,\n"," 'rougeL': 0.923076923076923,\n"," 'rougeLsum': 0.923076923076923}"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["# example of usage :\n","generated_summary = [\"I absolutely loved reading the Hunger Games\"]\n","reference_summary = [\"I loved reading the Hunger Games\"]\n","\n","scores = rouge_score.compute(\n","    predictions=generated_summary, references=reference_summary, use_stemmer=True\n",")\n","scores"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T10:47:40.185998Z","iopub.status.busy":"2024-06-22T10:47:40.185652Z","iopub.status.idle":"2024-06-22T10:47:40.394186Z","shell.execute_reply":"2024-06-22T10:47:40.393321Z","shell.execute_reply.started":"2024-06-22T10:47:40.185967Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'rouge1': 0.8365384615384615,\n"," 'rouge2': 0.6969696969696969,\n"," 'rougeL': 0.8365384615384615,\n"," 'rougeLsum': 0.8365384615384615}"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["# example on list :\n","generated_summary = [\"I absolutely loved reading the Hunger Games\", \"I like your shirt\"]\n","reference_summary = [\"I loved reading the Hunger Games\", \"I like your shit\"]\n","\n","scores = rouge_score.compute(\n","    predictions=generated_summary, references=reference_summary, use_stemmer=True\n",")\n","scores"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## 8/ Create the baseline model and evaluate the score of the baseline"]},{"cell_type":"markdown","metadata":{},"source":["### Create baseline :"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T10:47:40.395664Z","iopub.status.busy":"2024-06-22T10:47:40.395371Z","iopub.status.idle":"2024-06-22T10:47:40.549359Z","shell.execute_reply":"2024-06-22T10:47:40.548467Z","shell.execute_reply.started":"2024-06-22T10:47:40.395641Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}],"source":["# Create the baseline summary :\n","import nltk\n","nltk.download(\"punkt\")\n","from nltk.tokenize import sent_tokenize\n","\n","def three_sentence_summary(text):\n","    return \"\\n\".join(sent_tokenize(text)[:3])"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T10:47:40.550876Z","iopub.status.busy":"2024-06-22T10:47:40.550555Z","iopub.status.idle":"2024-06-22T10:47:40.569795Z","shell.execute_reply":"2024-06-22T10:47:40.568922Z","shell.execute_reply.started":"2024-06-22T10:47:40.550852Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Oli :  I've talked to some people from the third year | Jacob :  About the statistics exam?\n","| Marcia :  What did they say?\n","| Oli :  Yeah ,   about the exam | Oli :  We need to prepare for a battle | Jacob :  So it will be difficult | Oli :  They said it was the hardest exam ever | Marcia :   | Oli :  The questions were displayed on the screen | Oli :  One minute per question and it disappears | Oli :  They won't come back so if you didn't get your answer you're fucked | Marcia :  So we need to make the calculations really fast | Jacob :  That's insane | Oli :  I know | Oli :  Very stressful | Marcia :  How are we even supposed to study for it?\n"]}],"source":["# example of usage : \n","print(three_sentence_summary(tokenized_datasets[\"train\"][60][\"dialogue\"]))"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T10:47:40.571304Z","iopub.status.busy":"2024-06-22T10:47:40.570962Z","iopub.status.idle":"2024-06-22T10:47:40.576038Z","shell.execute_reply":"2024-06-22T10:47:40.575204Z","shell.execute_reply.started":"2024-06-22T10:47:40.571264Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["I'm romain.\n","you are paul.\n","We are a team.\n"]}],"source":["# Example 2 : \n","print(three_sentence_summary(\"I'm romain. you are paul. We are a team. yohou!\"))"]},{"cell_type":"markdown","metadata":{},"source":["### Evaluate baseline :"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T10:47:40.577402Z","iopub.status.busy":"2024-06-22T10:47:40.577140Z","iopub.status.idle":"2024-06-22T10:47:40.585857Z","shell.execute_reply":"2024-06-22T10:47:40.584766Z","shell.execute_reply.started":"2024-06-22T10:47:40.577380Z"},"trusted":true},"outputs":[],"source":["# evaluate baseline on validation set (val1) :\n","def evaluate_baseline(dataset, metric):\n","    summaries_baseline = [three_sentence_summary(text) for text in dataset[\"dialogue\"]]\n","    return metric.compute(predictions=summaries_baseline, references=dataset[\"summary\"])"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T10:47:40.587196Z","iopub.status.busy":"2024-06-22T10:47:40.586915Z","iopub.status.idle":"2024-06-22T10:47:42.255533Z","shell.execute_reply":"2024-06-22T10:47:42.254513Z","shell.execute_reply.started":"2024-06-22T10:47:40.587173Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'rouge1': 30.32, 'rouge2': 9.86, 'rougeL': 23.82, 'rougeLsum': 26.28}"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","\n","score = evaluate_baseline(tokenized_datasets[\"val1\"], rouge_score)\n","rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n","rouge_dict = dict((rn, round(score[rn] * 100, 2)) for rn in rouge_names)\n","rouge_dict"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## 9/ Fine-tuned the T5-small model (with TrainerAPI)"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T10:47:42.257109Z","iopub.status.busy":"2024-06-22T10:47:42.256801Z","iopub.status.idle":"2024-06-22T10:47:44.736541Z","shell.execute_reply":"2024-06-22T10:47:44.735627Z","shell.execute_reply.started":"2024-06-22T10:47:42.257084Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ee37217a88274a26950123cf81235c1a","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b799185d585f414f9b7b6483c343714d","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"575f21dfbc2b4dfaa6eaef20f14cd6a3","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["T5ForConditionalGeneration(\n","  (shared): Embedding(32128, 512)\n","  (encoder): T5Stack(\n","    (embed_tokens): Embedding(32128, 512)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=512, bias=False)\n","              (k): Linear(in_features=512, out_features=512, bias=False)\n","              (v): Linear(in_features=512, out_features=512, bias=False)\n","              (o): Linear(in_features=512, out_features=512, bias=False)\n","              (relative_attention_bias): Embedding(32, 8)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=512, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-5): 5 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=512, bias=False)\n","              (k): Linear(in_features=512, out_features=512, bias=False)\n","              (v): Linear(in_features=512, out_features=512, bias=False)\n","              (o): Linear(in_features=512, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=512, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (decoder): T5Stack(\n","    (embed_tokens): Embedding(32128, 512)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=512, bias=False)\n","              (k): Linear(in_features=512, out_features=512, bias=False)\n","              (v): Linear(in_features=512, out_features=512, bias=False)\n","              (o): Linear(in_features=512, out_features=512, bias=False)\n","              (relative_attention_bias): Embedding(32, 8)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=512, bias=False)\n","              (k): Linear(in_features=512, out_features=512, bias=False)\n","              (v): Linear(in_features=512, out_features=512, bias=False)\n","              (o): Linear(in_features=512, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=512, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-5): 5 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=512, bias=False)\n","              (k): Linear(in_features=512, out_features=512, bias=False)\n","              (v): Linear(in_features=512, out_features=512, bias=False)\n","              (o): Linear(in_features=512, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=512, bias=False)\n","              (k): Linear(in_features=512, out_features=512, bias=False)\n","              (v): Linear(in_features=512, out_features=512, bias=False)\n","              (o): Linear(in_features=512, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=512, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",")"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["# Load the model :\n","from transformers import AutoModelForSeq2SeqLM\n","\n","model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n","\n","# Attribute the devise to the model :\n","model.to(device)"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T10:47:44.738267Z","iopub.status.busy":"2024-06-22T10:47:44.737897Z","iopub.status.idle":"2024-06-22T10:47:44.742984Z","shell.execute_reply":"2024-06-22T10:47:44.741994Z","shell.execute_reply.started":"2024-06-22T10:47:44.738234Z"},"trusted":true},"outputs":[],"source":["# Notebook login :\n","# from huggingface_hub import notebook_login\n","\n","# notebook_login()"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T10:47:44.744698Z","iopub.status.busy":"2024-06-22T10:47:44.744301Z","iopub.status.idle":"2024-06-22T10:47:44.756621Z","shell.execute_reply":"2024-06-22T10:47:44.755471Z","shell.execute_reply.started":"2024-06-22T10:47:44.744667Z"},"trusted":true},"outputs":[],"source":["# Set the evaluation function :\n","import numpy as np\n","\n","\n","def compute_metrics(eval_pred):\n","    predictions, labels = eval_pred\n","    # Decode generated summaries into text\n","    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n","    # Replace -100 in the labels as we can't decode them\n","    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","    # Decode reference summaries into text\n","    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","    # ROUGE expects a newline after each sentence\n","    decoded_preds = [\"\\n\".join(sent_tokenize(pred.strip())) for pred in decoded_preds]\n","    decoded_labels = [\"\\n\".join(sent_tokenize(label.strip())) for label in decoded_labels]\n","    # Compute ROUGE scores\n","    result = rouge_score.compute(\n","        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n","    )\n","    # Extract the median scores # to review : value.mid.fmeasure <=> value\n","    result = {key: value * 100 for key, value in result.items()}\n","    return {k: round(v, 4) for k, v in result.items()}"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T10:47:44.759149Z","iopub.status.busy":"2024-06-22T10:47:44.757713Z","iopub.status.idle":"2024-06-22T10:47:44.764568Z","shell.execute_reply":"2024-06-22T10:47:44.763543Z","shell.execute_reply.started":"2024-06-22T10:47:44.759118Z"},"trusted":true},"outputs":[],"source":["# Define a data collator for the sequence-to-sequence task :\n","from transformers import DataCollatorForSeq2Seq\n","\n","data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"]},{"cell_type":"raw","metadata":{},"source":["##### Example of data collator :\n","tokenized_datasets2 = tokenized_datasets.remove_columns(Datadict[\"train\"].column_names)\n","\n","features = [tokenized_datasets2[\"train\"][i] for i in range(2)]\n","print(features)\n","\n","data_collator(features)"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T10:47:44.765932Z","iopub.status.busy":"2024-06-22T10:47:44.765632Z","iopub.status.idle":"2024-06-22T10:47:44.817522Z","shell.execute_reply":"2024-06-22T10:47:44.816641Z","shell.execute_reply.started":"2024-06-22T10:47:44.765910Z"},"trusted":true},"outputs":[],"source":["# Set the training argument:\n","from transformers import Seq2SeqTrainingArguments, TrainingArguments\n","\n","\"\"\"\n","Gradient Accumulation: effectively increase the batch size without needing more GPU memory.\n","Learning Rate Scheduler: better learning rate management during training.\n","Mixed Precision Training: Enable mixed precision training to speed up training and reduce memory usage.\n","\"\"\"\n","\n","batch_size = 5 #5\n","num_train_epochs = 30 #30\n","# Show the training loss with every epoch\n","logging_steps = 1000 #len(tokenized_datasets[\"train\"]) // batch_size\n","model_name = model_checkpoint.split(\"/\")[-1]\n","\n","\n","args = Seq2SeqTrainingArguments(\n","    seed=0,\n","    output_dir=f\"../Model/{model_name}_Train_Args_en\",  # Checkpoint path\n","    # Warning evaluation_strategy <=> eval_strategy\n","    evaluation_strategy=\"steps\",  # Evaluate every logging step # or \"epoch\" or \"no\" \n","    learning_rate=5.6e-5,  # Learning rate ######\n","    weight_decay=0.01,  # Weight decay for AdamW parameters optimization ######\n","    num_train_epochs=num_train_epochs,  # Number of epochs ######\n","    gradient_accumulation_steps=2,  # Accumulate gradients over 2 steps to simulate larger batch size #######\n","    lr_scheduler_type=\"linear\",  # Use a linear scheduler for learning rate\n","    metric_for_best_model=\"rougeL\",  # Metric to determine the best model\n","    per_device_train_batch_size=batch_size, ######\n","    per_device_eval_batch_size=batch_size, ######\n","    predict_with_generate=True,  # Predict the summary in each step with the generate method\n","    logging_steps=logging_steps,  # Number of update steps between two logs\n","    push_to_hub=False,\n","    save_total_limit=2,\n","    load_best_model_at_end=True,  # Save the best model\n","    fp16=True,  # Enable mixed precision training\n","    save_steps=logging_steps,  # Save checkpoint every logging step  \n",")"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T10:47:44.819375Z","iopub.status.busy":"2024-06-22T10:47:44.819036Z","iopub.status.idle":"2024-06-22T11:52:08.628341Z","shell.execute_reply":"2024-06-22T11:52:08.627179Z","shell.execute_reply.started":"2024-06-22T10:47:44.819345Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n","dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  ········································\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/html":["wandb version 0.17.2 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.16.6"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20240622_110407-91b0ggx1</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/romainpen/huggingface/runs/91b0ggx1' target=\"_blank\">peachy-elevator-11</a></strong> to <a href='https://wandb.ai/romainpen/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/romainpen/huggingface' target=\"_blank\">https://wandb.ai/romainpen/huggingface</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/romainpen/huggingface/runs/91b0ggx1' target=\"_blank\">https://wandb.ai/romainpen/huggingface/runs/91b0ggx1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='736' max='736' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [736/736 47:38, Epoch 1/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Rouge1</th>\n","      <th>Rouge2</th>\n","      <th>Rougel</th>\n","      <th>Rougelsum</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>30</td>\n","      <td>4.998500</td>\n","      <td>0.523728</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.689500</td>\n","      <td>0.393278</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.447700</td>\n","      <td>0.332724</td>\n","      <td>1.043100</td>\n","      <td>0.345400</td>\n","      <td>0.791300</td>\n","      <td>0.983200</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.371100</td>\n","      <td>0.302017</td>\n","      <td>22.065600</td>\n","      <td>8.513000</td>\n","      <td>18.069400</td>\n","      <td>20.520500</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.333200</td>\n","      <td>0.291001</td>\n","      <td>34.696700</td>\n","      <td>13.953500</td>\n","      <td>29.195100</td>\n","      <td>32.003000</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.333600</td>\n","      <td>0.284961</td>\n","      <td>36.465000</td>\n","      <td>14.668400</td>\n","      <td>30.525300</td>\n","      <td>33.776700</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.323700</td>\n","      <td>0.281158</td>\n","      <td>36.743500</td>\n","      <td>15.138100</td>\n","      <td>30.786900</td>\n","      <td>34.168700</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.322600</td>\n","      <td>0.278601</td>\n","      <td>36.800800</td>\n","      <td>15.043400</td>\n","      <td>30.791900</td>\n","      <td>33.995400</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.309600</td>\n","      <td>0.276305</td>\n","      <td>37.150400</td>\n","      <td>15.379400</td>\n","      <td>31.301500</td>\n","      <td>34.378600</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.309500</td>\n","      <td>0.275093</td>\n","      <td>37.576800</td>\n","      <td>15.508200</td>\n","      <td>31.613900</td>\n","      <td>34.777300</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.306100</td>\n","      <td>0.273013</td>\n","      <td>37.723200</td>\n","      <td>15.737900</td>\n","      <td>31.842200</td>\n","      <td>34.935200</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.308200</td>\n","      <td>0.272264</td>\n","      <td>37.921800</td>\n","      <td>16.090000</td>\n","      <td>31.992500</td>\n","      <td>35.284100</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.308000</td>\n","      <td>0.271039</td>\n","      <td>38.132900</td>\n","      <td>16.479200</td>\n","      <td>32.434100</td>\n","      <td>35.564600</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.303200</td>\n","      <td>0.270282</td>\n","      <td>38.807900</td>\n","      <td>16.709900</td>\n","      <td>32.878700</td>\n","      <td>36.132600</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.307600</td>\n","      <td>0.269625</td>\n","      <td>38.384600</td>\n","      <td>16.612600</td>\n","      <td>32.512700</td>\n","      <td>35.645000</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.291400</td>\n","      <td>0.268838</td>\n","      <td>38.448500</td>\n","      <td>16.485800</td>\n","      <td>32.524300</td>\n","      <td>35.714800</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.303800</td>\n","      <td>0.268459</td>\n","      <td>38.443800</td>\n","      <td>16.486400</td>\n","      <td>32.532800</td>\n","      <td>35.790300</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.297300</td>\n","      <td>0.267577</td>\n","      <td>38.487600</td>\n","      <td>16.582700</td>\n","      <td>32.688800</td>\n","      <td>35.908500</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.298900</td>\n","      <td>0.267269</td>\n","      <td>38.378000</td>\n","      <td>16.541700</td>\n","      <td>32.660700</td>\n","      <td>35.749700</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.302100</td>\n","      <td>0.266952</td>\n","      <td>38.624600</td>\n","      <td>16.787600</td>\n","      <td>32.870300</td>\n","      <td>35.974800</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>0.293400</td>\n","      <td>0.266787</td>\n","      <td>38.592700</td>\n","      <td>16.913800</td>\n","      <td>32.882300</td>\n","      <td>35.907800</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>0.297300</td>\n","      <td>0.266455</td>\n","      <td>38.747300</td>\n","      <td>16.951700</td>\n","      <td>32.983800</td>\n","      <td>36.012600</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>0.294500</td>\n","      <td>0.266437</td>\n","      <td>38.573000</td>\n","      <td>16.828900</td>\n","      <td>32.834300</td>\n","      <td>35.881000</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>0.297500</td>\n","      <td>0.266401</td>\n","      <td>38.607100</td>\n","      <td>16.833500</td>\n","      <td>32.870800</td>\n","      <td>35.941900</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n"]},{"data":{"text/plain":["TrainOutput(global_step=736, training_loss=0.5219754913578862, metrics={'train_runtime': 3862.8844, 'train_samples_per_second': 7.627, 'train_steps_per_second': 0.191, 'total_flos': 7966489118244864.0, 'train_loss': 0.5219754913578862, 'epoch': 2.0})"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["# Instanciate the trainer (with the standard arguments):\n","from transformers import Seq2SeqTrainer\n","\n","trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=args,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"val1\"],\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics,\n",")\n","\n","# Launch the train :\n","trainer.train()"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T11:52:08.630817Z","iopub.status.busy":"2024-06-22T11:52:08.630449Z","iopub.status.idle":"2024-06-22T11:52:59.964132Z","shell.execute_reply":"2024-06-22T11:52:59.963121Z","shell.execute_reply.started":"2024-06-22T11:52:08.630783Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [41/41 00:47]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'eval_loss': 0.26645541191101074,\n"," 'eval_rouge1': 38.7473,\n"," 'eval_rouge2': 16.9517,\n"," 'eval_rougeL': 32.9838,\n"," 'eval_rougeLsum': 36.0126,\n"," 'eval_runtime': 51.3198,\n"," 'eval_samples_per_second': 15.939,\n"," 'eval_steps_per_second': 0.799,\n"," 'epoch': 2.0}"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["# Evaluate the model on the val1 set :\n","trainer.evaluate()"]},{"cell_type":"raw","metadata":{},"source":["ROUGE score interpretation :\n","> ROUGE-1 scores are excellent around 0.5, with scores above 0.5 considered good and 0.4 to 0.5 moderate. \n","> ROUGE-2 scores above 0.4 are good, and 0.2 to 0.4 are moderate. \n","> ROUGE-L scores are good around 0.4 and low at 0.3 to 0.4."]},{"cell_type":"raw","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":["## 10/ Save the model (localy) :"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T11:52:59.965925Z","iopub.status.busy":"2024-06-22T11:52:59.965535Z","iopub.status.idle":"2024-06-22T11:53:00.480008Z","shell.execute_reply":"2024-06-22T11:53:00.478882Z","shell.execute_reply.started":"2024-06-22T11:52:59.965892Z"},"trusted":true},"outputs":[],"source":["# save the model :\n","trainer.save_model(r'./T5_small_finetune_samsum_model')"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T11:53:00.481852Z","iopub.status.busy":"2024-06-22T11:53:00.481417Z","iopub.status.idle":"2024-06-22T11:53:01.481894Z","shell.execute_reply":"2024-06-22T11:53:01.480664Z","shell.execute_reply.started":"2024-06-22T11:53:00.481814Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"name":"stdout","output_type":"stream","text":["T5_small_finetune_samsum_model\twandb\n"]}],"source":["#!ls"]},{"cell_type":"raw","metadata":{"vscode":{"languageId":"raw"}},"source":["# download model from KAGGLE :\n","\n","# Step 1 : Zip the model folder \n","import shutil\n","shutil.make_archive(\"T5_small_finetune_samsum_model\", 'zip', \"T5_small_finetune_samsum_model\")\n","\n","# Step 2 : Create the download link of the model_folder.zip\n","from IPython.display import FileLink\n","FileLink(r'./T5_small_finetune_samsum_model.zip')\n","\n","# Step 3 : Click on the link for downloading the model_folder.zip"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T11:53:01.485846Z","iopub.status.busy":"2024-06-22T11:53:01.483463Z","iopub.status.idle":"2024-06-22T11:53:15.869534Z","shell.execute_reply":"2024-06-22T11:53:15.868444Z","shell.execute_reply.started":"2024-06-22T11:53:01.485815Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'/kaggle/working/t5-small_Train_Args_en.zip'"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["import shutil\n","shutil.make_archive(\"T5_small_finetune_samsum_model\", 'zip', \"T5_small_finetune_samsum_model\")\n","shutil.make_archive(\"t5-small_Train_Args_en\", 'zip', \"t5-small_Train_Args_en\")"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T11:53:15.871976Z","iopub.status.busy":"2024-06-22T11:53:15.871241Z","iopub.status.idle":"2024-06-22T11:53:15.880143Z","shell.execute_reply":"2024-06-22T11:53:15.879061Z","shell.execute_reply.started":"2024-06-22T11:53:15.871942Z"},"trusted":true},"outputs":[{"data":{"text/html":["<a href='./T5_small_finetune_samsum_model.zip' target='_blank'>./T5_small_finetune_samsum_model.zip</a><br>"],"text/plain":["/kaggle/working/T5_small_finetune_samsum_model.zip"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["# download the model\n","from IPython.display import FileLink\n","FileLink(r'./T5_small_finetune_samsum_model.zip')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# 11/ Valid the model by evaluating the model on the test set (val2)"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T11:53:15.882219Z","iopub.status.busy":"2024-06-22T11:53:15.881635Z","iopub.status.idle":"2024-06-22T11:53:15.889682Z","shell.execute_reply":"2024-06-22T11:53:15.888595Z","shell.execute_reply.started":"2024-06-22T11:53:15.882173Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'cuda:0'"]},"execution_count":47,"metadata":{},"output_type":"execute_result"}],"source":["# Define the devise (cuda or CPU) :\n","import torch\n","device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n","device"]},{"cell_type":"code","execution_count":48,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T11:53:15.891360Z","iopub.status.busy":"2024-06-22T11:53:15.890971Z","iopub.status.idle":"2024-06-22T11:53:16.856932Z","shell.execute_reply":"2024-06-22T11:53:16.855919Z","shell.execute_reply.started":"2024-06-22T11:53:15.891330Z"},"trusted":true},"outputs":[],"source":["# import model :\n","from transformers import pipeline\n","pipe = pipeline('summarization', model='./T5_small_finetune_samsum_model', device=device)"]},{"cell_type":"code","execution_count":50,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T11:59:26.838217Z","iopub.status.busy":"2024-06-22T11:59:26.837282Z","iopub.status.idle":"2024-06-22T12:05:36.352775Z","shell.execute_reply":"2024-06-22T12:05:36.351754Z","shell.execute_reply.started":"2024-06-22T11:59:26.838190Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f0696bc2e21241748ead207338564970","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/819 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Your min_length=30 must be inferior than your max_length=20.\n","Your min_length=30 must be inferior than your max_length=24.\n","Your min_length=30 must be inferior than your max_length=21.\n","Your min_length=30 must be inferior than your max_length=22.\n","Your min_length=30 must be inferior than your max_length=16.\n","Your min_length=30 must be inferior than your max_length=24.\n","Your min_length=30 must be inferior than your max_length=26.\n","Your min_length=30 must be inferior than your max_length=18.\n","Your min_length=30 must be inferior than your max_length=27.\n","Your min_length=30 must be inferior than your max_length=29.\n","Your min_length=30 must be inferior than your max_length=23.\n","Your min_length=30 must be inferior than your max_length=26.\n","Your min_length=30 must be inferior than your max_length=22.\n","Your min_length=30 must be inferior than your max_length=23.\n","Your min_length=30 must be inferior than your max_length=22.\n","Your min_length=30 must be inferior than your max_length=16.\n","Your min_length=30 must be inferior than your max_length=22.\n","Your min_length=30 must be inferior than your max_length=13.\n","Your min_length=30 must be inferior than your max_length=12.\n","Your min_length=30 must be inferior than your max_length=25.\n","Your min_length=30 must be inferior than your max_length=10.\n","Your min_length=30 must be inferior than your max_length=19.\n","Your min_length=30 must be inferior than your max_length=28.\n","Your min_length=30 must be inferior than your max_length=23.\n","Your min_length=30 must be inferior than your max_length=10.\n","Your min_length=30 must be inferior than your max_length=16.\n","Your min_length=30 must be inferior than your max_length=24.\n","Your min_length=30 must be inferior than your max_length=29.\n","Your min_length=30 must be inferior than your max_length=18.\n","Your min_length=30 must be inferior than your max_length=24.\n","Your min_length=30 must be inferior than your max_length=28.\n","Your min_length=30 must be inferior than your max_length=29.\n","Your min_length=30 must be inferior than your max_length=18.\n","Your min_length=30 must be inferior than your max_length=13.\n","Your min_length=30 must be inferior than your max_length=29.\n","Your min_length=30 must be inferior than your max_length=18.\n","Your min_length=30 must be inferior than your max_length=18.\n","Your min_length=30 must be inferior than your max_length=16.\n","Your min_length=30 must be inferior than your max_length=10.\n","Your min_length=30 must be inferior than your max_length=19.\n","Your min_length=30 must be inferior than your max_length=22.\n","Your min_length=30 must be inferior than your max_length=24.\n","Your min_length=30 must be inferior than your max_length=27.\n","Your min_length=30 must be inferior than your max_length=22.\n","Your min_length=30 must be inferior than your max_length=21.\n","Your min_length=30 must be inferior than your max_length=20.\n","Your min_length=30 must be inferior than your max_length=28.\n","Your min_length=30 must be inferior than your max_length=24.\n","Your min_length=30 must be inferior than your max_length=14.\n","Your min_length=30 must be inferior than your max_length=21.\n","Your min_length=30 must be inferior than your max_length=18.\n","Your min_length=30 must be inferior than your max_length=23.\n","Your min_length=30 must be inferior than your max_length=26.\n","Your min_length=30 must be inferior than your max_length=19.\n","Your min_length=30 must be inferior than your max_length=16.\n","Your min_length=30 must be inferior than your max_length=14.\n","Your min_length=30 must be inferior than your max_length=26.\n","Your min_length=30 must be inferior than your max_length=15.\n","Your min_length=30 must be inferior than your max_length=29.\n","Your min_length=30 must be inferior than your max_length=26.\n","Your min_length=30 must be inferior than your max_length=26.\n","Your min_length=30 must be inferior than your max_length=16.\n","Your min_length=30 must be inferior than your max_length=10.\n","Your min_length=30 must be inferior than your max_length=18.\n","Your min_length=30 must be inferior than your max_length=21.\n","Your min_length=30 must be inferior than your max_length=16.\n","Your min_length=30 must be inferior than your max_length=13.\n","Your min_length=30 must be inferior than your max_length=22.\n","Your min_length=30 must be inferior than your max_length=28.\n","Your min_length=30 must be inferior than your max_length=27.\n","Your min_length=30 must be inferior than your max_length=29.\n","Your min_length=30 must be inferior than your max_length=16.\n","Your min_length=30 must be inferior than your max_length=23.\n","Your min_length=30 must be inferior than your max_length=18.\n","Your min_length=30 must be inferior than your max_length=21.\n","Your min_length=30 must be inferior than your max_length=20.\n","Your min_length=30 must be inferior than your max_length=29.\n","Your min_length=30 must be inferior than your max_length=22.\n","Your min_length=30 must be inferior than your max_length=10.\n","Your min_length=30 must be inferior than your max_length=19.\n","Your min_length=30 must be inferior than your max_length=26.\n","Your min_length=30 must be inferior than your max_length=27.\n","Your min_length=30 must be inferior than your max_length=29.\n","Your min_length=30 must be inferior than your max_length=17.\n","Your min_length=30 must be inferior than your max_length=9.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1156: UserWarning: Unfeasible length constraints: `min_length` (30) is larger than the maximum possible length (9). Generation will stop at the defined maximum length. You should decrease the minimum length and/or increase the maximum length.\n","  warnings.warn(\n","Your min_length=30 must be inferior than your max_length=16.\n","Your min_length=30 must be inferior than your max_length=26.\n","Your min_length=30 must be inferior than your max_length=24.\n","Your min_length=30 must be inferior than your max_length=19.\n","Your min_length=30 must be inferior than your max_length=12.\n","Your min_length=30 must be inferior than your max_length=26.\n","Your min_length=30 must be inferior than your max_length=26.\n","Your min_length=30 must be inferior than your max_length=22.\n","Your min_length=30 must be inferior than your max_length=26.\n","Your min_length=30 must be inferior than your max_length=26.\n","Your min_length=30 must be inferior than your max_length=21.\n","Your min_length=30 must be inferior than your max_length=25.\n","Your min_length=30 must be inferior than your max_length=22.\n","Your min_length=30 must be inferior than your max_length=15.\n","Your min_length=30 must be inferior than your max_length=20.\n","Your min_length=30 must be inferior than your max_length=19.\n","Your min_length=30 must be inferior than your max_length=26.\n","Your min_length=30 must be inferior than your max_length=21.\n","Your min_length=30 must be inferior than your max_length=14.\n","Your min_length=30 must be inferior than your max_length=25.\n","Your min_length=30 must be inferior than your max_length=14.\n","Your min_length=30 must be inferior than your max_length=21.\n","Your min_length=30 must be inferior than your max_length=28.\n","Your min_length=30 must be inferior than your max_length=28.\n","Your min_length=30 must be inferior than your max_length=10.\n","Your min_length=30 must be inferior than your max_length=28.\n","Your min_length=30 must be inferior than your max_length=16.\n","Your min_length=30 must be inferior than your max_length=19.\n","Your min_length=30 must be inferior than your max_length=27.\n","Your min_length=30 must be inferior than your max_length=17.\n","Your min_length=30 must be inferior than your max_length=16.\n","Your min_length=30 must be inferior than your max_length=24.\n","Your min_length=30 must be inferior than your max_length=18.\n","Your min_length=30 must be inferior than your max_length=29.\n","Your min_length=30 must be inferior than your max_length=13.\n","Your min_length=30 must be inferior than your max_length=11.\n","Your min_length=30 must be inferior than your max_length=14.\n","Your min_length=30 must be inferior than your max_length=29.\n","Your min_length=30 must be inferior than your max_length=29.\n","Your min_length=30 must be inferior than your max_length=22.\n","Your min_length=30 must be inferior than your max_length=20.\n","Your min_length=30 must be inferior than your max_length=24.\n","Your min_length=30 must be inferior than your max_length=21.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7789f90dbdb64087a6abd0426cc5e1f7","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/819 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["Dataset({\n","    features: ['id', 'dialogue', 'summary', 'pred'],\n","    num_rows: 819\n","})"]},"execution_count":50,"metadata":{},"output_type":"execute_result"}],"source":[" # Compute pred \n","gen_kwargs = {'length_penalty': 0.8, 'num_beams': 8}\n","Datadict_val2_pred = Datadict[\"val2\"].map(lambda df: {\"pred\": [pipe(txt, max_length=round(len(txt)*0.15), **gen_kwargs) for txt in df[\"dialogue\"]]}, batched=True)\n","Datadict_val2_pred = Datadict_val2_pred.map(lambda df: {\"pred\": [[dict_pred[\"summary_text\"] for dict_pred in pred][0] for pred in df[\"pred\"]]}, batched=True)\n","Datadict_val2_pred"]},{"cell_type":"code","execution_count":51,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T12:05:36.354670Z","iopub.status.busy":"2024-06-22T12:05:36.354295Z","iopub.status.idle":"2024-06-22T12:05:38.714758Z","shell.execute_reply":"2024-06-22T12:05:38.713110Z","shell.execute_reply.started":"2024-06-22T12:05:36.354638Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'rouge1': 0.4256796396394038,\n"," 'rouge2': 0.18693666736403164,\n"," 'rougeL': 0.3368827190422622,\n"," 'rougeLsum': 0.336705303134342}"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["# Compute rouge score\n","rouge_score.compute(predictions=Datadict_val2_pred[\"pred\"], references=Datadict_val2_pred[\"summary\"], use_stemmer=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## 12/ Analyse the model by testing on ONE example "]},{"cell_type":"code","execution_count":53,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T12:12:22.577875Z","iopub.status.busy":"2024-06-22T12:12:22.577461Z","iopub.status.idle":"2024-06-22T12:12:24.038121Z","shell.execute_reply":"2024-06-22T12:12:24.037015Z","shell.execute_reply.started":"2024-06-22T12:12:22.577844Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Your min_length=30 must be inferior than your max_length=25.\n"]},{"name":"stdout","output_type":"stream","text":["Carla will tidy the table first . Romain will wait a minute for her to clear the room .\n"]}],"source":["from transformers import pipeline\n","\n","pipe = pipeline('summarization', model='./T5_small_finetune_samsum_model')\n","\n","custom_dialogue=\"\"\"\n","Romain: Hey ! Can you help me to clear the room ? \n","Carla: Yes I can. Could you wait me a minute ? \n","Romain: Yes of course, I will tidy the table first. \n","Carla: Nice ! \n","\"\"\"\n","\n","# Manage the output length :\n","# Output_length (=max_length) == [10% ; 15%] * input_lenght\n","gen_kwargs = {'length_penalty': 0.8, 'num_beams': 8, \"max_length\": round(len(custom_dialogue)*0.15)}\n","print(pipe(custom_dialogue, **gen_kwargs)[0][\"summary_text\"])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## 13/ Deploy the model in real situation"]},{"cell_type":"code","execution_count":54,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T12:12:25.629408Z","iopub.status.busy":"2024-06-22T12:12:25.628781Z","iopub.status.idle":"2024-06-22T12:12:25.676250Z","shell.execute_reply":"2024-06-22T12:12:25.674989Z","shell.execute_reply.started":"2024-06-22T12:12:25.629375Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>dialogue</th>\n","      <th>summary</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>13862856</td>\n","      <td>Hannah: Hey, do you have Betty's number?\\nAman...</td>\n","      <td>Hannah needs Betty's number but Amanda doesn't...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>13729565</td>\n","      <td>Eric: MACHINE!\\nRob: That's so gr8!\\nEric: I k...</td>\n","      <td>Eric and Rob are going to watch a stand-up on ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>13680171</td>\n","      <td>Lenny: Babe, can you help me with something?\\n...</td>\n","      <td>Lenny can't decide which trousers to buy. Bob ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>13729438</td>\n","      <td>Will: hey babe, what do you want for dinner to...</td>\n","      <td>Emma will be home soon and she will let Will k...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>13828600</td>\n","      <td>Ollie: Hi , are you in Warsaw\\nJane: yes, just...</td>\n","      <td>Jane is in Warsaw. Ollie and Jane has a party....</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>814</th>\n","      <td>13611902-1</td>\n","      <td>Alex: Were you able to attend Friday night's b...</td>\n","      <td>Benjamin didn't come to see a basketball game ...</td>\n","    </tr>\n","    <tr>\n","      <th>815</th>\n","      <td>13820989</td>\n","      <td>Jamilla: remember that the audition starts at ...</td>\n","      <td>The audition starts at 7.30 P.M. in Antena 3.</td>\n","    </tr>\n","    <tr>\n","      <th>816</th>\n","      <td>13717193</td>\n","      <td>Marta: &lt;file_gif&gt;\\nMarta: Sorry girls, I click...</td>\n","      <td>Marta sent a file accidentally,</td>\n","    </tr>\n","    <tr>\n","      <th>817</th>\n","      <td>13829115</td>\n","      <td>Cora: Have you heard how much fuss British med...</td>\n","      <td>There was a meet-and-greet with James Charles ...</td>\n","    </tr>\n","    <tr>\n","      <th>818</th>\n","      <td>13818810</td>\n","      <td>Rachel: &lt;file_other&gt;\\nRachel: Top 50 Best Film...</td>\n","      <td>Rachel sends a list of Top 50 films of 2018. J...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>819 rows × 3 columns</p>\n","</div>"],"text/plain":["             id                                           dialogue  \\\n","0      13862856  Hannah: Hey, do you have Betty's number?\\nAman...   \n","1      13729565  Eric: MACHINE!\\nRob: That's so gr8!\\nEric: I k...   \n","2      13680171  Lenny: Babe, can you help me with something?\\n...   \n","3      13729438  Will: hey babe, what do you want for dinner to...   \n","4      13828600  Ollie: Hi , are you in Warsaw\\nJane: yes, just...   \n","..          ...                                                ...   \n","814  13611902-1  Alex: Were you able to attend Friday night's b...   \n","815    13820989  Jamilla: remember that the audition starts at ...   \n","816    13717193  Marta: <file_gif>\\nMarta: Sorry girls, I click...   \n","817    13829115  Cora: Have you heard how much fuss British med...   \n","818    13818810  Rachel: <file_other>\\nRachel: Top 50 Best Film...   \n","\n","                                               summary  \n","0    Hannah needs Betty's number but Amanda doesn't...  \n","1    Eric and Rob are going to watch a stand-up on ...  \n","2    Lenny can't decide which trousers to buy. Bob ...  \n","3    Emma will be home soon and she will let Will k...  \n","4    Jane is in Warsaw. Ollie and Jane has a party....  \n","..                                                 ...  \n","814  Benjamin didn't come to see a basketball game ...  \n","815      The audition starts at 7.30 P.M. in Antena 3.  \n","816                    Marta sent a file accidentally,  \n","817  There was a meet-and-greet with James Charles ...  \n","818  Rachel sends a list of Top 50 films of 2018. J...  \n","\n","[819 rows x 3 columns]"]},"execution_count":54,"metadata":{},"output_type":"execute_result"}],"source":["# Import df_val2_brut :\n","df_val2_brut = pd.read_parquet(r\"/kaggle/input/data-txt-summarisation/Data/deployment_testing_data/conv_val2_brut.parquet\", engine=\"pyarrow\")\n","df_val2_brut"]},{"cell_type":"code","execution_count":55,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T12:13:11.716570Z","iopub.status.busy":"2024-06-22T12:13:11.715661Z","iopub.status.idle":"2024-06-22T12:13:12.168083Z","shell.execute_reply":"2024-06-22T12:13:12.166836Z","shell.execute_reply.started":"2024-06-22T12:13:11.716535Z"},"trusted":true},"outputs":[],"source":["# Import model :\n","from transformers import pipeline\n","model_txtsum = pipeline('summarization', model='./T5_small_finetune_samsum_model', device=device)"]},{"cell_type":"raw","metadata":{"vscode":{"languageId":"raw"}},"source":["# Expose all function used in API_simulation function :\n","\n","# Data cleaning function : \n","def data_cleaning_1(df, col_to_rename=None, col_type=None, useless_columns=None):\n","    \n","    # Deep copy : \n","    df_new = df.copy()\n","    \n","    # Rename columns if col_to_rename is provided and not empty\n","    if col_to_rename:\n","        df_new = df_new.rename(columns=col_to_rename)\n","    \n","    # Check and change column types if col_type is provided\n","    if col_type:\n","        for col in df_new.columns : \n","            df_new[col] = df_new[col].astype(col_type[col])\n","            \n","    # Drop useless columns if useless_columns is provided\n","    if useless_columns:\n","        df_new = df_new.drop(list(useless_columns), axis=1)\n","    \n","    # Remove duplicates\n","    df_new = df_new.drop_duplicates().reset_index(drop=True)\n","    \n","    # Remove rows with NaN in \"dialogue\" or \"summary\"\n","    df_new = df_new.dropna(subset=[\"dialogue\", \"summary\"], ignore_index=True).reset_index(drop=True)\n","    \n","    return df_new\n","\n","\n","# Rename col \n","col_to_rename = {\"id\" : \"id\", \"dialogue\" : \"dialogue\", \"summary\" : \"summary\"}\n","# Change col type \n","col_type = {\"id\" : \"object\", \"dialogue\" : \"object\", \"summary\" : \"object\"}\n","# Delete useless col\n","useless_columns = None\n","\n","kwarg_dc1 = {\"col_to_rename\": col_to_rename, \"col_type\": col_type, \"useless_columns\":useless_columns}\n","df_new = data_cleaning_1(df=df, **kwarg_dc1)\n","\n","\n","\n","# Check Language consistency (english txt == english summary), by hand : #Already done\n"]},{"cell_type":"raw","metadata":{},"source":["# Normalized txt :\n","import html\n","import re\n","\n","\n","def normalized_txt(df):\n","    processed_dialogue = []\n","    processed_summary = []\n","    \n","    for text in df[\"dialogue\"]:\n","        text = process_text(text)\n","        processed_dialogue.append(text)\n","    \n","    for text in df[\"summary\"]:\n","        text = process_text(text)\n","        processed_summary.append(text)\n","    \n","    return {\"dialogue\": processed_dialogue, \"summary\": processed_summary}\n","\n","\n","\n","def process_text(text):\n","    # Remove HTML tags\n","    text = html.unescape(text)\n","    \n","    # Lowercase\n","    # text = text.lower()\n","    \n","    # Remove extra spaces at the start and end\n","    text = text.strip()\n","    \n","    # Replace control characters (\\r, \\n, \\t) with ' | '\n","    text = re.sub(r'[\\r\\n\\t]', ' | ', text)\n","    \n","    # Remove redundant spaces within the text\n","    text = \" \".join(text.split())\n","    \n","    # STANDARDIZE PUNCTUATION :\n","    # Convert different types of quotation marks and apostrophes to standard forms\n","    text = text.replace('“', '\"').replace('”', '\"')\n","    text = text.replace(\"‘\", \"'\").replace(\"’\", \"'\")\n","    \n","    # Ensure consistent spacing around punctuation\n","    text = re.sub(r'([?.!,%£$€\"])', r'\\1 ', text)  # Remove spaces before punctuation and Ensure space after punctuation (except at end of string)\n","    text = re.sub(r'([&:+-=;])', r' \\1 ', text)\n","    \n","    # Convert special punctuation to standard forms (example: em dash to hyphen)\n","    #text = text.replace('—', '-').replace('–', '-')\n","    \n","    # REMOVE or REPLACE USELESS CHARACTERS :\n","    # Remove URLs\n","    #text = re.sub(r'http\\S+|www\\S+|https\\S+', '<Web_site_link>', text, flags=re.MULTILINE)\n","    \n","    # Remove email addresses\n","    #text = re.sub(r'\\S+@\\S+', '<email_address>', text)\n","    \n","    # Remove non-ASCII characters\n","    text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n","    \n","    return text\n","\n","\n","# Apply the combined function to the dataset\n","Datadict = Datadict.map(normalized_txt, batched=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":56,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T12:13:17.278272Z","iopub.status.busy":"2024-06-22T12:13:17.277651Z","iopub.status.idle":"2024-06-22T12:13:17.290770Z","shell.execute_reply":"2024-06-22T12:13:17.289740Z","shell.execute_reply.started":"2024-06-22T12:13:17.278239Z"},"trusted":true},"outputs":[],"source":["def API_simulation(data:pd.DataFrame, input_col_name:str, model) :\n","    # -------------- Data cleaning 1 : ---------------------\n","    # Rename col : {\"old_name\" : \"new_name\"}\n","    col_to_rename = {\"id\" : \"id\", \"dialogue\" : \"dialogue\", \"summary\" : \"summary\"}\n","\n","    # Change col type \n","    col_type = {\"id\" : \"object\", \"dialogue\" : \"object\", \"summary\" : \"object\"}\n","\n","    # Delete useless col\n","    useless_columns = None\n","\n","    # Data cleaning funct\n","    kwarg_dc1 = {\"col_to_rename\": col_to_rename, \"col_type\": col_type, \"useless_columns\":useless_columns}\n","    df = data_cleaning_1(df=data, **kwarg_dc1)\n","\n","\n","    # ------------- Data cleaning 2 : ----------------------\n","    # Pandas DF to Datasets\n","    dataset_df = Dataset.from_pandas(df)\n","\n","    # Normalized_txt\n","    dataset_df = dataset_df.map(normalized_txt, batched=True)\n","\n","    # Correct spelling and grammar : Done\n","    # remove noise : Done\n","\n","    # Handle emoji\n","    dataset_df = dataset_df.map(lambda df: {col_to_rename[input_col_name]: [emoji.demojize(txt) for txt in df[col_to_rename[input_col_name]]]}, batched=True)\n","\n","    # [option] correct consistency : Done\n","    # [option] correct consistency in Formatting : Done\n","    # [option] Data filter (select specific txt) : Done\n","\n","\n","    # -------------------- Predict  ------------------------\n","    # Compute pred \n","    gen_kwargs = {'length_penalty': 0.8, 'num_beams': 8}\n","    dataset_df_pred = dataset_df.map(lambda df: {\"pred\": [model(txt, max_length=round(len(txt)*0.15), **gen_kwargs) for txt in df[col_to_rename[input_col_name]]]}, batched=True)\n"," \n","    # transform output/pred into list\n","    dataset_df_pred = dataset_df_pred.map(lambda df: {\"pred\": [[dict_pred[\"summary_text\"] for dict_pred in pred][0] for pred in df[\"pred\"]]}, batched=True)\n","\n","\n","    # --------- Create the new_data as pd.DataFrame -----------\n","    df_output = pd.DataFrame(dataset_df_pred)\n","\n","\n","    # ---------------- Return the new_data ----------------\n","    return df_output\n","\n"]},{"cell_type":"code","execution_count":57,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T12:13:19.572487Z","iopub.status.busy":"2024-06-22T12:13:19.572113Z","iopub.status.idle":"2024-06-22T12:19:36.670375Z","shell.execute_reply":"2024-06-22T12:19:36.668840Z","shell.execute_reply.started":"2024-06-22T12:13:19.572458Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ab7b20e3ff44498eb9a43dee7ea8b66a","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/819 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5ce77a147a004a7e8ec6911866389e02","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/819 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"797ab51a54a14efe9425e5019359e84f","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/819 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Your min_length=30 must be inferior than your max_length=20.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1156: UserWarning: Unfeasible length constraints: `min_length` (30) is larger than the maximum possible length (20). Generation will stop at the defined maximum length. You should decrease the minimum length and/or increase the maximum length.\n","  warnings.warn(\n","Token indices sequence length is longer than the specified maximum sequence length for this model (608 > 512). Running this sequence through the model will result in indexing errors\n","Your min_length=30 must be inferior than your max_length=24.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1156: UserWarning: Unfeasible length constraints: `min_length` (30) is larger than the maximum possible length (24). Generation will stop at the defined maximum length. You should decrease the minimum length and/or increase the maximum length.\n","  warnings.warn(\n","Your min_length=30 must be inferior than your max_length=21.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1156: UserWarning: Unfeasible length constraints: `min_length` (30) is larger than the maximum possible length (21). Generation will stop at the defined maximum length. You should decrease the minimum length and/or increase the maximum length.\n","  warnings.warn(\n","Your min_length=30 must be inferior than your max_length=22.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1156: UserWarning: Unfeasible length constraints: `min_length` (30) is larger than the maximum possible length (22). Generation will stop at the defined maximum length. You should decrease the minimum length and/or increase the maximum length.\n","  warnings.warn(\n","Your min_length=30 must be inferior than your max_length=16.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1156: UserWarning: Unfeasible length constraints: `min_length` (30) is larger than the maximum possible length (16). Generation will stop at the defined maximum length. You should decrease the minimum length and/or increase the maximum length.\n","  warnings.warn(\n","Your min_length=30 must be inferior than your max_length=24.\n","Your min_length=30 must be inferior than your max_length=26.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1156: UserWarning: Unfeasible length constraints: `min_length` (30) is larger than the maximum possible length (26). Generation will stop at the defined maximum length. You should decrease the minimum length and/or increase the maximum length.\n","  warnings.warn(\n","Your min_length=30 must be inferior than your max_length=18.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1156: UserWarning: Unfeasible length constraints: `min_length` (30) is larger than the maximum possible length (18). Generation will stop at the defined maximum length. You should decrease the minimum length and/or increase the maximum length.\n","  warnings.warn(\n","Your min_length=30 must be inferior than your max_length=27.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1156: UserWarning: Unfeasible length constraints: `min_length` (30) is larger than the maximum possible length (27). Generation will stop at the defined maximum length. You should decrease the minimum length and/or increase the maximum length.\n","  warnings.warn(\n","Your min_length=30 must be inferior than your max_length=29.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1156: UserWarning: Unfeasible length constraints: `min_length` (30) is larger than the maximum possible length (29). Generation will stop at the defined maximum length. You should decrease the minimum length and/or increase the maximum length.\n","  warnings.warn(\n","Your min_length=30 must be inferior than your max_length=23.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1156: UserWarning: Unfeasible length constraints: `min_length` (30) is larger than the maximum possible length (23). Generation will stop at the defined maximum length. You should decrease the minimum length and/or increase the maximum length.\n","  warnings.warn(\n","Your min_length=30 must be inferior than your max_length=26.\n","Your min_length=30 must be inferior than your max_length=22.\n","Your min_length=30 must be inferior than your max_length=23.\n","Your min_length=30 must be inferior than your max_length=22.\n","Your min_length=30 must be inferior than your max_length=16.\n","Your min_length=30 must be inferior than your max_length=22.\n","Your min_length=30 must be inferior than your max_length=13.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1156: UserWarning: Unfeasible length constraints: `min_length` (30) is larger than the maximum possible length (13). Generation will stop at the defined maximum length. You should decrease the minimum length and/or increase the maximum length.\n","  warnings.warn(\n","Your min_length=30 must be inferior than your max_length=12.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1156: UserWarning: Unfeasible length constraints: `min_length` (30) is larger than the maximum possible length (12). Generation will stop at the defined maximum length. You should decrease the minimum length and/or increase the maximum length.\n","  warnings.warn(\n","Your min_length=30 must be inferior than your max_length=25.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1156: UserWarning: Unfeasible length constraints: `min_length` (30) is larger than the maximum possible length (25). Generation will stop at the defined maximum length. You should decrease the minimum length and/or increase the maximum length.\n","  warnings.warn(\n","Your min_length=30 must be inferior than your max_length=10.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1156: UserWarning: Unfeasible length constraints: `min_length` (30) is larger than the maximum possible length (10). Generation will stop at the defined maximum length. You should decrease the minimum length and/or increase the maximum length.\n","  warnings.warn(\n","Your min_length=30 must be inferior than your max_length=19.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1156: UserWarning: Unfeasible length constraints: `min_length` (30) is larger than the maximum possible length (19). Generation will stop at the defined maximum length. You should decrease the minimum length and/or increase the maximum length.\n","  warnings.warn(\n","Your min_length=30 must be inferior than your max_length=28.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1156: UserWarning: Unfeasible length constraints: `min_length` (30) is larger than the maximum possible length (28). Generation will stop at the defined maximum length. You should decrease the minimum length and/or increase the maximum length.\n","  warnings.warn(\n","Your min_length=30 must be inferior than your max_length=23.\n","Your min_length=30 must be inferior than your max_length=10.\n","Your min_length=30 must be inferior than your max_length=16.\n","Your min_length=30 must be inferior than your max_length=24.\n","Your min_length=30 must be inferior than your max_length=29.\n","Your min_length=30 must be inferior than your max_length=18.\n","Your min_length=30 must be inferior than your max_length=24.\n","Your min_length=30 must be inferior than your max_length=28.\n","Your min_length=30 must be inferior than your max_length=29.\n","Your min_length=30 must be inferior than your max_length=18.\n","Your min_length=30 must be inferior than your max_length=13.\n","Your min_length=30 must be inferior than your max_length=29.\n","Your min_length=30 must be inferior than your max_length=18.\n","Your min_length=30 must be inferior than your max_length=18.\n","Your min_length=30 must be inferior than your max_length=16.\n","Your min_length=30 must be inferior than your max_length=10.\n","Your min_length=30 must be inferior than your max_length=19.\n","Your min_length=30 must be inferior than your max_length=22.\n","Your min_length=30 must be inferior than your max_length=24.\n","Your min_length=30 must be inferior than your max_length=27.\n","Your min_length=30 must be inferior than your max_length=22.\n","Your min_length=30 must be inferior than your max_length=21.\n","Your min_length=30 must be inferior than your max_length=20.\n","Your min_length=30 must be inferior than your max_length=28.\n","Your min_length=30 must be inferior than your max_length=24.\n","Your min_length=30 must be inferior than your max_length=14.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1156: UserWarning: Unfeasible length constraints: `min_length` (30) is larger than the maximum possible length (14). Generation will stop at the defined maximum length. You should decrease the minimum length and/or increase the maximum length.\n","  warnings.warn(\n","Your min_length=30 must be inferior than your max_length=21.\n","Your min_length=30 must be inferior than your max_length=18.\n","Your min_length=30 must be inferior than your max_length=23.\n","Your min_length=30 must be inferior than your max_length=26.\n","Your min_length=30 must be inferior than your max_length=19.\n","Your min_length=30 must be inferior than your max_length=16.\n","Your min_length=30 must be inferior than your max_length=14.\n","Your min_length=30 must be inferior than your max_length=26.\n","Your min_length=30 must be inferior than your max_length=15.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1156: UserWarning: Unfeasible length constraints: `min_length` (30) is larger than the maximum possible length (15). Generation will stop at the defined maximum length. You should decrease the minimum length and/or increase the maximum length.\n","  warnings.warn(\n","Your min_length=30 must be inferior than your max_length=29.\n","Your min_length=30 must be inferior than your max_length=26.\n","Your min_length=30 must be inferior than your max_length=26.\n","Your min_length=30 must be inferior than your max_length=16.\n","Your min_length=30 must be inferior than your max_length=10.\n","Your min_length=30 must be inferior than your max_length=18.\n","Your min_length=30 must be inferior than your max_length=21.\n","Your min_length=30 must be inferior than your max_length=16.\n","Your min_length=30 must be inferior than your max_length=13.\n","Your min_length=30 must be inferior than your max_length=22.\n","Your min_length=30 must be inferior than your max_length=28.\n","Your min_length=30 must be inferior than your max_length=27.\n","Your min_length=30 must be inferior than your max_length=29.\n","Your min_length=30 must be inferior than your max_length=16.\n","Your min_length=30 must be inferior than your max_length=23.\n","Your min_length=30 must be inferior than your max_length=18.\n","Your min_length=30 must be inferior than your max_length=21.\n","Your min_length=30 must be inferior than your max_length=20.\n","Your min_length=30 must be inferior than your max_length=29.\n","Your min_length=30 must be inferior than your max_length=22.\n","Your min_length=30 must be inferior than your max_length=10.\n","Your min_length=30 must be inferior than your max_length=19.\n","Your min_length=30 must be inferior than your max_length=26.\n","Your min_length=30 must be inferior than your max_length=27.\n","Your min_length=30 must be inferior than your max_length=29.\n","Your min_length=30 must be inferior than your max_length=17.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1156: UserWarning: Unfeasible length constraints: `min_length` (30) is larger than the maximum possible length (17). Generation will stop at the defined maximum length. You should decrease the minimum length and/or increase the maximum length.\n","  warnings.warn(\n","Your min_length=30 must be inferior than your max_length=9.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1156: UserWarning: Unfeasible length constraints: `min_length` (30) is larger than the maximum possible length (9). Generation will stop at the defined maximum length. You should decrease the minimum length and/or increase the maximum length.\n","  warnings.warn(\n","Your min_length=30 must be inferior than your max_length=16.\n","Your min_length=30 must be inferior than your max_length=26.\n","Your min_length=30 must be inferior than your max_length=24.\n","Your min_length=30 must be inferior than your max_length=19.\n","Your min_length=30 must be inferior than your max_length=12.\n","Your min_length=30 must be inferior than your max_length=26.\n","Your min_length=30 must be inferior than your max_length=26.\n","Your min_length=30 must be inferior than your max_length=22.\n","Your min_length=30 must be inferior than your max_length=26.\n","Your min_length=30 must be inferior than your max_length=26.\n","Your min_length=30 must be inferior than your max_length=21.\n","Your min_length=30 must be inferior than your max_length=25.\n","Your min_length=30 must be inferior than your max_length=22.\n","Your min_length=30 must be inferior than your max_length=15.\n","Your min_length=30 must be inferior than your max_length=20.\n","Your min_length=30 must be inferior than your max_length=19.\n","Your min_length=30 must be inferior than your max_length=26.\n","Your min_length=30 must be inferior than your max_length=21.\n","Your min_length=30 must be inferior than your max_length=14.\n","Your min_length=30 must be inferior than your max_length=25.\n","Your min_length=30 must be inferior than your max_length=14.\n","Your min_length=30 must be inferior than your max_length=21.\n","Your min_length=30 must be inferior than your max_length=28.\n","Your min_length=30 must be inferior than your max_length=28.\n","Your min_length=30 must be inferior than your max_length=10.\n","Your min_length=30 must be inferior than your max_length=28.\n","Your min_length=30 must be inferior than your max_length=16.\n","Your min_length=30 must be inferior than your max_length=19.\n","Your min_length=30 must be inferior than your max_length=27.\n","Your min_length=30 must be inferior than your max_length=17.\n","Your min_length=30 must be inferior than your max_length=16.\n","Your min_length=30 must be inferior than your max_length=24.\n","Your min_length=30 must be inferior than your max_length=18.\n","Your min_length=30 must be inferior than your max_length=29.\n","Your min_length=30 must be inferior than your max_length=13.\n","Your min_length=30 must be inferior than your max_length=11.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1156: UserWarning: Unfeasible length constraints: `min_length` (30) is larger than the maximum possible length (11). Generation will stop at the defined maximum length. You should decrease the minimum length and/or increase the maximum length.\n","  warnings.warn(\n","Your min_length=30 must be inferior than your max_length=14.\n","Your min_length=30 must be inferior than your max_length=29.\n","Your min_length=30 must be inferior than your max_length=29.\n","Your min_length=30 must be inferior than your max_length=22.\n","Your min_length=30 must be inferior than your max_length=20.\n","Your min_length=30 must be inferior than your max_length=24.\n","Your min_length=30 must be inferior than your max_length=21.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f9cf31fda6694940adf643777e61c48c","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/819 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>dialogue</th>\n","      <th>summary</th>\n","      <th>pred</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>13862856</td>\n","      <td>Hannah :  Hey ,   do you have Betty's number? ...</td>\n","      <td>Hannah needs Betty's number but Amanda doesn't...</td>\n","      <td>Amanda can't find Betty's number . He called h...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>13729565</td>\n","      <td>Eric :  MACHINE!  | Rob :  That's so gr 8 !  |...</td>\n","      <td>Eric and Rob are going to watch a stand - up o...</td>\n","      <td>Eric likes the train part . Rob will watch som...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>13680171</td>\n","      <td>Lenny :  Babe ,   can you help me with somethi...</td>\n","      <td>Lenny can't decide which trousers to buy .   B...</td>\n","      <td>Bob has four black pairs . Lenny will buy the ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>13729438</td>\n","      <td>Will :  hey babe ,   what do you want for dinn...</td>\n","      <td>Emma will be home soon and she will let Will k...</td>\n","      <td>Emma will be home soon , but she'll pick her u...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>13828600</td>\n","      <td>Ollie :  Hi  ,   are you in Warsaw | Jane :  y...</td>\n","      <td>Jane is in Warsaw .   Ollie and Jane has a par...</td>\n","      <td>Ollie is in Warsaw for a diner on the 1 9 th ....</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>814</th>\n","      <td>13611902-1</td>\n","      <td>Alex :  Were you able to attend Friday night's...</td>\n","      <td>Benjamin didn't come to see a basketball game ...</td>\n","      <td>Alex was unable to attend Friday night's baske...</td>\n","    </tr>\n","    <tr>\n","      <th>815</th>\n","      <td>13820989</td>\n","      <td>Jamilla :  remember that the audition starts a...</td>\n","      <td>The audition starts at  7  .   3  0  P .  M . ...</td>\n","      <td>Jamilla's audition starts at 7 . 3 0 P . M .</td>\n","    </tr>\n","    <tr>\n","      <th>816</th>\n","      <td>13717193</td>\n","      <td>Marta :   &lt; file_gif&gt; | Marta :  Sorry girls ,...</td>\n","      <td>Marta sent a file accidentally ,</td>\n","      <td>Marta clicked a file_gif by accident . Weronik...</td>\n","    </tr>\n","    <tr>\n","      <th>817</th>\n","      <td>13829115</td>\n","      <td>Cora :  Have you heard how much fuss British m...</td>\n","      <td>There was a meet - and - greet with James Char...</td>\n","      <td>a meet and greet with James Charles in one of ...</td>\n","    </tr>\n","    <tr>\n","      <th>818</th>\n","      <td>13818810</td>\n","      <td>Rachel :   &lt; file_other&gt; | Rachel :  Top  5  0...</td>\n","      <td>Rachel sends a list of Top  5  0  films of  2 ...</td>\n","      <td>Janice's bf forced her to watch Deadpool 2 2 t...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>819 rows × 4 columns</p>\n","</div>"],"text/plain":["             id                                           dialogue  \\\n","0      13862856  Hannah :  Hey ,   do you have Betty's number? ...   \n","1      13729565  Eric :  MACHINE!  | Rob :  That's so gr 8 !  |...   \n","2      13680171  Lenny :  Babe ,   can you help me with somethi...   \n","3      13729438  Will :  hey babe ,   what do you want for dinn...   \n","4      13828600  Ollie :  Hi  ,   are you in Warsaw | Jane :  y...   \n","..          ...                                                ...   \n","814  13611902-1  Alex :  Were you able to attend Friday night's...   \n","815    13820989  Jamilla :  remember that the audition starts a...   \n","816    13717193  Marta :   < file_gif> | Marta :  Sorry girls ,...   \n","817    13829115  Cora :  Have you heard how much fuss British m...   \n","818    13818810  Rachel :   < file_other> | Rachel :  Top  5  0...   \n","\n","                                               summary  \\\n","0    Hannah needs Betty's number but Amanda doesn't...   \n","1    Eric and Rob are going to watch a stand - up o...   \n","2    Lenny can't decide which trousers to buy .   B...   \n","3    Emma will be home soon and she will let Will k...   \n","4    Jane is in Warsaw .   Ollie and Jane has a par...   \n","..                                                 ...   \n","814  Benjamin didn't come to see a basketball game ...   \n","815  The audition starts at  7  .   3  0  P .  M . ...   \n","816                 Marta sent a file accidentally ,     \n","817  There was a meet - and - greet with James Char...   \n","818  Rachel sends a list of Top  5  0  films of  2 ...   \n","\n","                                                  pred  \n","0    Amanda can't find Betty's number . He called h...  \n","1    Eric likes the train part . Rob will watch som...  \n","2    Bob has four black pairs . Lenny will buy the ...  \n","3    Emma will be home soon , but she'll pick her u...  \n","4    Ollie is in Warsaw for a diner on the 1 9 th ....  \n","..                                                 ...  \n","814  Alex was unable to attend Friday night's baske...  \n","815       Jamilla's audition starts at 7 . 3 0 P . M .  \n","816  Marta clicked a file_gif by accident . Weronik...  \n","817  a meet and greet with James Charles in one of ...  \n","818  Janice's bf forced her to watch Deadpool 2 2 t...  \n","\n","[819 rows x 4 columns]"]},"execution_count":57,"metadata":{},"output_type":"execute_result"}],"source":["# Run the API_simulation function on val2\n","df_val2_pred = API_simulation(data=df_val2_brut, input_col_name=\"dialogue\", model=model_txtsum)\n","df_val2_pred"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-22T12:05:39.619806Z","iopub.status.idle":"2024-06-22T12:05:39.620497Z","shell.execute_reply":"2024-06-22T12:05:39.620266Z","shell.execute_reply.started":"2024-06-22T12:05:39.620245Z"},"trusted":true},"outputs":[],"source":["# Save the output :\n","# df_val2_pred.to_csv()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## 14/ Check if the Deployment is good"]},{"cell_type":"raw","metadata":{"vscode":{"languageId":"raw"}},"source":["Compute the rouge_score of df_val2_brut (output of deployment pipeline)\n","Compare this score with the rouge_score of df_val2 (df used during the training)\n","If df_val2_brut rouge_score == df_val2 rouge_score : GOOD\n","else : PROBLEM"]},{"cell_type":"code","execution_count":58,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T12:19:36.672554Z","iopub.status.busy":"2024-06-22T12:19:36.672175Z","iopub.status.idle":"2024-06-22T12:19:37.027021Z","shell.execute_reply":"2024-06-22T12:19:37.025923Z","shell.execute_reply.started":"2024-06-22T12:19:36.672522Z"},"trusted":true},"outputs":[],"source":["# Rouge-score :\n","import evaluate\n","rouge_score = evaluate.load(\"rouge\")"]},{"cell_type":"code","execution_count":59,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T12:19:37.028938Z","iopub.status.busy":"2024-06-22T12:19:37.028496Z","iopub.status.idle":"2024-06-22T12:19:39.408846Z","shell.execute_reply":"2024-06-22T12:19:39.407814Z","shell.execute_reply.started":"2024-06-22T12:19:37.028897Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'rouge1': 0.42599040666575716,\n"," 'rouge2': 0.1870667509171463,\n"," 'rougeL': 0.336804997068584,\n"," 'rougeLsum': 0.3368439087449549}"]},"execution_count":59,"metadata":{},"output_type":"execute_result"}],"source":["# Compute rouge score (dict) :\n","# 1st option/ Compare with the rouge score obtained in the step 11\n","rouge_score.compute(predictions=df_val2_pred[\"pred\"], references=df_val2_pred[\"summary\"], use_stemmer=True)"]},{"cell_type":"code","execution_count":60,"metadata":{"execution":{"iopub.execute_input":"2024-06-22T12:19:39.411353Z","iopub.status.busy":"2024-06-22T12:19:39.410948Z","iopub.status.idle":"2024-06-22T12:19:41.755988Z","shell.execute_reply":"2024-06-22T12:19:41.754498Z","shell.execute_reply.started":"2024-06-22T12:19:39.411318Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'rouge1': 1.0, 'rouge2': 1.0, 'rougeL': 1.0, 'rougeLsum': 1.0}"]},"execution_count":60,"metadata":{},"output_type":"execute_result"}],"source":["# 2nd option/ Or compute the rouge_score between pred from step 11 and the pred from step 13 :\n","rouge_score.compute(predictions=df_val2_pred[\"pred\"], references=Datadict_val2_pred[\"pred\"], use_stemmer=True)"]},{"cell_type":"raw","metadata":{},"source":["The result are the same (or all rouge_score==1), so :\n","The API_simulation is operational. "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5104576,"sourceId":8543874,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":4}
